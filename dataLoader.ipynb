{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bfb061e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy\n",
    "import random\n",
    "import pdb\n",
    "import os\n",
    "import threading\n",
    "import time\n",
    "import math\n",
    "import glob\n",
    "import soundfile\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import librosa\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24cbc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class train_loader(object):\n",
    "    def __init__(self, train_list, train_path, musan_path, rir_path, num_frames, **kwargs):\n",
    "        self.train_path = train_path\n",
    "        self.num_frames = num_frames\n",
    "        # Load and configure augmentation files\n",
    "        self.noisetypes = ['noise','speech','music']\n",
    "        self.noisesnr = {'noise':[0,15],'speech':[13,20],'music':[5,15]}\n",
    "        self.numnoise = {'noise':[1,1], 'speech':[3,8], 'music':[1,1]}\n",
    "        self.noiselist = {}\n",
    "        augment_files   = glob.glob(os.path.join(musan_path,'*/*/*/*.wav'))\n",
    "        for file in augment_files:\n",
    "            if file.split('/')[-3] not in self.noiselist:\n",
    "                self.noiselist[file.split('/')[-3]] = []\n",
    "            self.noiselist[file.split('/')[-3]].append(file)\n",
    "        self.rir_files  = glob.glob(os.path.join(rir_path,'*/*/*.wav'))\n",
    "        # Load data & labels\n",
    "        self.data_list  = []\n",
    "        self.data_label = []\n",
    "        lines = open(train_list).read().splitlines()\n",
    "        dictkeys = list(set([x.split()[0] for x in lines]))\n",
    "        dictkeys.sort()\n",
    "        dictkeys = { key : ii for ii, key in enumerate(dictkeys) }\n",
    "        for index, line in enumerate(lines):\n",
    "            speaker_label = dictkeys[line.split()[0]]\n",
    "            file_name     = os.path.join(train_path, line.split()[1])\n",
    "            self.data_label.append(speaker_label)\n",
    "            self.data_list.append(file_name)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Read the utterance and randomly select the segment\n",
    "        audio, sr = soundfile.read(self.data_list[index])\n",
    "        length = self.num_frames * 160 + 240\n",
    "        if audio.shape[0] <= length:\n",
    "            shortage = length - audio.shape[0]\n",
    "            audio = numpy.pad(audio, (0, shortage), 'wrap')\n",
    "        start_frame = numpy.int64(random.random()*(audio.shape[0]-length))\n",
    "        audio = audio[start_frame:start_frame + length]\n",
    "        audio = numpy.stack([audio],axis=0)\n",
    "        # Data Augmentation\n",
    "        augtype = random.randint(0,0)\n",
    "        if augtype == 0:   # Original\n",
    "            audio = audio\n",
    "        elif augtype == 1: # Reverberation\n",
    "            audio = self.add_rev(audio)\n",
    "        elif augtype == 2: # Babble\n",
    "            audio = self.add_noise(audio, 'speech')\n",
    "        elif augtype == 3: # Music\n",
    "            audio = self.add_noise(audio, 'music')\n",
    "        elif augtype == 4: # Noise\n",
    "            audio = self.add_noise(audio, 'noise')\n",
    "        elif augtype == 5: # Television noise\n",
    "            audio = self.add_noise(audio, 'speech')\n",
    "            audio = self.add_noise(audio, 'music')\n",
    "        return torch.FloatTensor(audio[0]), self.data_label[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def add_rev(self, audio):\n",
    "        rir_file    = random.choice(self.rir_files)\n",
    "        rir, sr     = soundfile.read(rir_file)\n",
    "        rir         = numpy.expand_dims(rir.astype(numpy.float),0)\n",
    "        rir         = rir / numpy.sqrt(numpy.sum(rir**2))\n",
    "        return signal.convolve(audio, rir, mode='full')[:,:self.num_frames * 160 + 240]\n",
    "\n",
    "    def add_noise(self, audio, noisecat):\n",
    "        clean_db    = 10 * numpy.log10(numpy.mean(audio ** 2)+1e-4) \n",
    "        numnoise    = self.numnoise[noisecat]\n",
    "        noiselist   = random.sample(self.noiselist[noisecat], random.randint(numnoise[0],numnoise[1]))\n",
    "        noises = []\n",
    "        for noise in noiselist:\n",
    "            noiseaudio, sr = soundfile.read(noise)\n",
    "            length = self.num_frames * 160 + 240\n",
    "            if noiseaudio.shape[0] <= length:\n",
    "                shortage = length - noiseaudio.shape[0]\n",
    "                noiseaudio = numpy.pad(noiseaudio, (0, shortage), 'wrap')\n",
    "            start_frame = numpy.int64(random.random()*(noiseaudio.shape[0]-length))\n",
    "            noiseaudio = noiseaudio[start_frame:start_frame + length]\n",
    "            noiseaudio = numpy.stack([noiseaudio],axis=0)\n",
    "            noise_db = 10 * numpy.log10(numpy.mean(noiseaudio ** 2)+1e-4) \n",
    "            noisesnr   = random.uniform(self.noisesnr[noisecat][0],self.noisesnr[noisecat][1])\n",
    "            noises.append(numpy.sqrt(10 ** ((clean_db - noise_db - noisesnr) / 10)) * noiseaudio)\n",
    "        noise = numpy.sum(numpy.concatenate(noises,axis=0),axis=0,keepdims=True)\n",
    "        return noise + audio"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
